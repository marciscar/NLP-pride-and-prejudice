{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfa108d2-e50a-4f39-9eb9-e05974307ef6",
   "metadata": {},
   "source": [
    "# Pride and prejudice text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10327d5e-b376-4db6-a8bc-209af42502aa",
   "metadata": {},
   "source": [
    "## Imports and loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a56c4278-d7c1-4378-9e3b-a15d1aab041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0224e1d3-1e93-4fc0-bbab-a6e3a5c67f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/pride_and_prejudice.txt','r',encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e366b633-e94b-443f-bb4c-e42da435e453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nIt is a truth universally acknowledged, that a single man in possession\\nof a good fortune, must be in want of a wife.\\n\\nHowever little known the feelings or views of such a man may be on his\\nfirst entering a neighbourhood, this truth is so well fixed in the minds\\nof the surrounding families, that he is considered the rightful property\\nof some one or other of their daughters.\\n\\n“My dear Mr. Bennet,” said his lady to him one day, “have you heard that\\nNetherfield Park is let at last?”\\n\\nMr. Bennet replied that he had not.\\n\\n“But it is,” returned she; “for Mrs. Long has just been here, and she\\ntold me all about it.”\\n\\nMr. Bennet made no answer.\\n\\n“Do you not want to know who has taken it?” cried his wife impatiently.\\n\\n“_You_ want to tell me, and I have no objection to hearing it.”\\n\\nThis was invitation enough.\\n\\n“Why, my dear, you must know, Mrs. Long says that Netherfield is taken\\nby a young man of large fortune from the north of England; that he came\\ndown on Monday in a chaise and fo'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5ded624-6668-4ce9-953d-856b0954323a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1\n",
      "\n",
      "\n",
      "It is a truth universally acknowledged, that a single man in possession\n",
      "of a good fortune, must be in want of a wife.\n",
      "\n",
      "However little known the feelings or views of such a man may be on his\n",
      "first entering a neighbourhood, this truth is so well fixed in the minds\n",
      "of the surrounding families, that he is considered the rightful property\n",
      "of some one or other of their daughters.\n",
      "\n",
      "“My dear Mr. Bennet,” said his lady to him one day, “have you heard that\n",
      "Netherfield Park is let at last?”\n",
      "\n",
      "Mr. Bennet replied that he had not.\n",
      "\n",
      "“But it is,” returned she; “for Mrs. Long has just been here, and she\n",
      "told me all about it.”\n",
      "\n",
      "Mr. Bennet made no answer.\n",
      "\n",
      "“Do you not want to know who has taken it?” cried his wife impatiently.\n",
      "\n",
      "“_You_ want to tell me, and I have no objection to hearing it.”\n",
      "\n",
      "This was invitation enough.\n",
      "\n",
      "“Why, my dear, you must know, Mrs. Long says that Netherfield is taken\n",
      "by a young man of large fortune from the north of England; that he came\n",
      "down on Monday in a chaise and fo\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8758aae-1642-496c-98a2-2290cbd23b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684743"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bf277-8f40-4507-9f16-bf8b5ccfecd4",
   "metadata": {},
   "source": [
    "## Encode entire text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d350d8-d003-4a2a-b2f6-fc18e057d2b0",
   "metadata": {},
   "source": [
    "We create an encoder and a decoder for each character in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0ba77f7-774a-4453-8fdf-5e4f4542730f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_characters = set(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d477247-bcea-4bb3-945d-8a23deade064",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = dict(enumerate(all_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59bd2795-535d-416b-8b9e-cc42947d7c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([(0, 't'), (1, '-'), (2, 'R'), (3, 'p'), (4, 's'), (5, 'Z'), (6, 'T'), (7, 'd'), (8, ';'), (9, 'z'), (10, '7'), (11, 'D'), (12, 'j'), (13, '9'), (14, 'c'), (15, '_'), (16, ' '), (17, 'N'), (18, 'q'), (19, \"'\"), (20, 'b'), (21, '('), (22, 'k'), (23, 'w'), (24, 'M'), (25, 'r'), (26, 'm'), (27, ':'), (28, '4'), (29, '3'), (30, 'L'), (31, 'Y'), (32, 'W'), (33, 'l'), (34, ')'), (35, 'O'), (36, '*'), (37, '5'), (38, '.'), (39, 'v'), (40, 'J'), (41, '1'), (42, 'a'), (43, '!'), (44, '2'), (45, 'B'), (46, 'u'), (47, 'h'), (48, 'e'), (49, '\\n'), (50, 'f'), (51, 'F'), (52, 'P'), (53, '“'), (54, 'H'), (55, 'S'), (56, 'C'), (57, 'i'), (58, 'E'), (59, 'G'), (60, 'I'), (61, 'A'), (62, '8'), (63, '?'), (64, 'y'), (65, '6'), (66, 'U'), (67, '0'), (68, 'g'), (69, 'K'), (70, 'V'), (71, ','), (72, '”'), (73, 'o'), (74, 'x'), (75, 'n')])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f09e2d9b-920b-4937-a870-2dacd5437a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = {char: ind for ind,char in decoder.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "682e9661-b897-46d9-834a-59818f8caad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56, 47, 42,  3,  0, 48, 25, 16, 41, 49, 49, 49, 60,  0, 16, 57,  4,\n",
       "       16, 42, 16,  0, 25, 46,  0, 47, 16, 46, 75, 57, 39, 48, 25,  4, 42,\n",
       "       33, 33, 64, 16, 42, 14, 22, 75, 73, 23, 33, 48,  7, 68, 48,  7, 71,\n",
       "       16,  0, 47, 42,  0, 16, 42, 16,  4, 57, 75, 68, 33, 48, 16, 26, 42,\n",
       "       75, 16, 57, 75, 16,  3, 73,  4,  4, 48,  4,  4, 57, 73, 75, 49, 73,\n",
       "       50, 16, 42, 16, 68, 73, 73,  7, 16, 50, 73, 25,  0, 46, 75])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text = np.array([encoder[char] for char in text])\n",
    "encoded_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "221ebc13-28a1-431a-a43d-e46658a0d654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder[56]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef333bd-08d0-468c-b7d2-984965f66c9e",
   "metadata": {},
   "source": [
    "**We one-hot encode our data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1e3ad30-7b54-47a4-947d-e211f9a88035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(encoded_text, num_uni_chars):\n",
    "    '''\n",
    "    encoded_text : batch of encoded text\n",
    "    \n",
    "    num_uni_chars = number of unique characters (len(set(text)))\n",
    "    '''\n",
    "    \n",
    "    # METHOD FROM:\n",
    "    # https://stackoverflow.com/questions/29831489/convert-encoded_textay-of-indices-to-1-hot-encoded-numpy-encoded_textay\n",
    "      \n",
    "    # Create a placeholder for zeros.\n",
    "    one_hot = np.zeros((encoded_text.size, num_uni_chars))\n",
    "    \n",
    "    # Convert data type for later use with pytorch\n",
    "    one_hot = one_hot.astype(np.float32)\n",
    "\n",
    "    # Using fancy indexing fill in the 1s at the correct index locations\n",
    "    one_hot[np.arange(one_hot.shape[0]), encoded_text.flatten()] = 1.0\n",
    "    \n",
    "    # Reshape it so it matches the batch shape\n",
    "    one_hot = one_hot.reshape((*encoded_text.shape, num_uni_chars))\n",
    "    \n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b183e9c-fbd7-4d54-9944-5365fc3880aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot_encoder(np.array([1,2,0]),3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be751f1-0e6c-4c13-aab4-87b8ea37f173",
   "metadata": {},
   "source": [
    "## Create the training batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d530075-68f0-46af-901e-62ce89f7887e",
   "metadata": {},
   "source": [
    "We create a function that will generate batches of characters along with the next character in the sequence as a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a2f37f6-f9c4-4bb3-8f81-59677c22636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(encoded_text, samp_per_batch=10, seq_len=50):\n",
    "    \n",
    "    '''\n",
    "    Generate batches for training.\n",
    "    \n",
    "    X: Encoded Text of length seq_len\n",
    "    Y: Encoded Text shifted by one\n",
    "    \n",
    "    Example:\n",
    "    \n",
    "    x:\n",
    "    \n",
    "    [[1 2 3]]\n",
    "    \n",
    "    y:\n",
    "    \n",
    "    [[2 3 4]]\n",
    "    \n",
    "    encoded_text : Complete Encoded Text to make batches from\n",
    "    samp_per_batch : Number of samples (sequences) per batch\n",
    "    seq_len : Length of character sequence\n",
    "       \n",
    "    '''\n",
    "    \n",
    "    # Total number of characters per batch:\n",
    "    char_per_batch = samp_per_batch * seq_len\n",
    "    \n",
    "    # Number of batches available to make (rounded down to integer)\n",
    "    num_batches_avail = int(np.floor(len(encoded_text)/char_per_batch))\n",
    "    \n",
    "    # Cut off end of encoded_text that won't fit evenly into a batch\n",
    "    encoded_text = encoded_text[:num_batches_avail * char_per_batch]\n",
    "    \n",
    "    # Reshape text into samp_per_batch rows\n",
    "    encoded_text = encoded_text.reshape((samp_per_batch, -1))\n",
    "    \n",
    "    # Go through each row in array.\n",
    "    for n in range(0, encoded_text.shape[1], seq_len):\n",
    "        \n",
    "        # Grab feature characters\n",
    "        x = encoded_text[:, n:n+seq_len]\n",
    "        \n",
    "        # Go through each row in array.\n",
    "        y = np.zeros_like(x)\n",
    "       \n",
    "        try:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1]  = encoded_text[:, n+seq_len]\n",
    "            \n",
    "        # End of the row:    \n",
    "        except:\n",
    "            y[:, :-1] = x[:, 1:]\n",
    "            y[:, -1] = encoded_text[:, 0]\n",
    "            \n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb59ab-b25e-4946-b7bc-b05b94b02993",
   "metadata": {},
   "source": [
    "### Example of generating a batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6cfdf76e-fb2b-4d9f-8186-46ea3db86018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56, 47, 42,  3,  0, 48, 25, 16, 41, 49, 49, 49, 60,  0, 16, 57,  4,\n",
       "       16, 42, 16])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = encoded_text[:20]\n",
    "sample_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10ece794-3a53-4362-8099-69784df2a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_generator = generate_batches(sample_text, samp_per_batch=2, seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69b2a7fe-4721-47d1-8137-5a98770dae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab first batch\n",
    "x, y = next(batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bada9009-422e-487c-a3ba-31041a33db0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 25, 16, 41, 49],\n",
       "       [57,  4, 16, 42, 16]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e5724994-659e-4d5f-af4e-40ab038027c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25, 16, 41, 49, 56],\n",
       "       [ 4, 16, 42, 16, 49]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30192a9c-a008-4058-a532-77b2ed01d995",
   "metadata": {},
   "source": [
    "## Creating the LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e77b1bdf-2943-4890-8785-69b3daeeca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, all_chars, num_hidden=256, num_layers=4, drop_prob=0.5, use_gpu=False):\n",
    "        \n",
    "        \n",
    "        # SET UP ATTRIBUTES\n",
    "        super().__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden = num_hidden\n",
    "        self.use_gpu = use_gpu\n",
    "        \n",
    "        #CHARACTER SET, ENCODER, and DECODER\n",
    "        self.all_chars = all_chars\n",
    "        self.decoder = dict(enumerate(all_chars))\n",
    "        self.encoder = {char: ind for ind,char in decoder.items()}\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(len(self.all_chars), num_hidden, num_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        self.fc_linear = nn.Linear(num_hidden, len(self.all_chars))\n",
    "      \n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "                  \n",
    "        \n",
    "        lstm_output, hidden = self.lstm(x, hidden)\n",
    "        \n",
    "        \n",
    "        drop_output = self.dropout(lstm_output)\n",
    "        \n",
    "        drop_output = drop_output.contiguous().view(-1, self.num_hidden)\n",
    "        \n",
    "        \n",
    "        final_out = self.fc_linear(drop_output)\n",
    "        \n",
    "        \n",
    "        return final_out, hidden\n",
    "    \n",
    "    \n",
    "    def hidden_state(self, batch_size):\n",
    "        '''\n",
    "        Used as separate method to account for both GPU and CPU users.\n",
    "        '''\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            \n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda(),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden).cuda())\n",
    "        else:\n",
    "            hidden = (torch.zeros(self.num_layers,batch_size,self.num_hidden),\n",
    "                     torch.zeros(self.num_layers,batch_size,self.num_hidden))\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a443be-7ba2-49ff-bfae-088158d60d53",
   "metadata": {},
   "source": [
    "## Instance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c5b8ae13-1397-4cee-8137-4da6506e7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharModel(\n",
    "    all_chars=all_characters,\n",
    "    num_hidden=128,\n",
    "    num_layers=3,\n",
    "    drop_prob=0.5,\n",
    "    use_gpu=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "00ded145-6c39-4f2d-b317-d7f3999c24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_param  = []\n",
    "for p in model.parameters():\n",
    "    total_param.append(int(p.numel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f52432e8-f609-4dbe-afd0-2ed29a62b198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379468"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1211c223-10c2-428d-a48d-891a327af2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "684743"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1231fc-6aa7-44b7-9885-ab8f2f3d5b4f",
   "metadata": {},
   "source": [
    "The number of parameters is roughly of the same magnitude of the total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e6170cf-6fb9-4b3b-b6f0-a93099eda565",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78511e3-50db-43ae-9976-ccfd9b5f93c2",
   "metadata": {},
   "source": [
    "## Training Data and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64832f3-8ec1-433c-8879-e609abc06cb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc709a28-b6dd-480e-9fa3-967b5270f057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f508c3c-0114-4ccb-a957-39e62c624db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7bf7d-ee5d-4a25-8f39-aab0415aa682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82865efb-a5a1-4f28-b7c0-33d5e5278c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86db026-1348-4220-a099-1db20d55cefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536d83f-7328-47fe-acb5-9b127ffacd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df345f05-edd7-4708-a807-1176cd151b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f573b7b-c4a1-470a-8e23-690bb09af1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
